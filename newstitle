from bs4 import BeautifulSoup
import requests
from urllib.error import HTTPError
from urllib.request import urlopen
from urllib.error import URLError
import csv
import re

csvFile = open('test.csv','w+',encoding='UTF-8')
writer = csv.writer(csvFile)
for url in range(1,10):
    global pages
    html = urlopen('https://www.ceoscoredaily.com/news?page={}'.format(url))
    bs = BeautifulSoup(html,'html.parser')
    titlelist = bs.find('div',{'id':'container'}).findAll('p',{'class':'title'})
    for title in titlelist:
        writer.writerow((title.text,''))

csvFile.close()







